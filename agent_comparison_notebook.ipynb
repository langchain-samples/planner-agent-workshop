{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agent Comparison: LangChain vs DeepAgents\n",
        "\n",
        "This notebook shows how to build the **same calendar agent** in two ways:\n",
        "\n",
        "1. **LangChain** – `create_agent` with model, tools, and system prompt\n",
        "2. **DeepAgents** – `create_deep_agent` with built-in planning, file system, and optional subagents\n",
        "\n",
        "Both use the same tools and model; DeepAgents add planning and context management on top."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. LangSmith setup\n",
        "\n",
        "LangSmith gives you tracing, debugging, and visibility into agent runs.\n",
        "\n",
        "**Setup steps:**\n",
        "\n",
        "1. Sign up at [smith.langchain.com](https://smith.langchain.com)\n",
        "2. Create an API key: **Settings → API Keys → Create API Key**\n",
        "3. Add to your `.env` (see `.env.example`):\n",
        "   ```\n",
        "   LANGSMITH_API_KEY=your_api_key_here\n",
        "   LANGSMITH_TRACING=true\n",
        "   LANGSMITH_PROJECT=your-project-name\n",
        "   ```\n",
        "\n",
        "See `.env.example` in the project root. With this in place, runs are automatically sent to LangSmith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LangSmith configured (traces will appear in your project)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# Optional: enable tracing if not set in .env\n",
        "os.environ.setdefault(\"LANGSMITH_TRACING\", \"true\")\n",
        "os.environ.setdefault(\"LANGSMITH_PROJECT\", \"agent-comparison\")\n",
        "\n",
        "if os.getenv(\"LANGSMITH_API_KEY\"):\n",
        "    print(\"✅ LangSmith configured (traces will appear in your project)\")\n",
        "else:\n",
        "    print(\"⚠️ LANGSMITH_API_KEY not set — add it to .env for tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment and shared pieces\n",
        "\n",
        "Imports, model, and shared calendar tools used by both agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model: ChatOpenAI\n",
            "✅ Calendar tools defined\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Model (same for both agents)\n",
        "model = init_chat_model(\"gpt-4o-mini\", temperature=0)\n",
        "print(f\"✅ Model: {model.__class__.__name__}\")\n",
        "\n",
        "# Shared in-memory calendar\n",
        "_calendar_events: List[Dict] = []\n",
        "\n",
        "@tool\n",
        "def read_calendar(date: str = None) -> str:\n",
        "    \"\"\"Read calendar events. If date is provided, filter events for that date (YYYY-MM-DD).\"\"\"\n",
        "    if date:\n",
        "        filtered = [e for e in _calendar_events if e.get(\"date\") == date]\n",
        "        if not filtered:\n",
        "            return f\"No events found for {date}\"\n",
        "        return \"\\n\".join([f\"- {e['title']} on {e['date']} at {e['time']} in {e.get('location', 'N/A')}\" for e in filtered])\n",
        "    if not _calendar_events:\n",
        "        return \"No events in calendar\"\n",
        "    return \"\\n\".join([f\"- {e['title']} on {e['date']} at {e['time']} in {e.get('location', 'N/A')}\" for e in _calendar_events])\n",
        "\n",
        "@tool\n",
        "def write_calendar(title: str, date: str, time: str, location: str = \"\") -> str:\n",
        "    \"\"\"Create a new calendar event. Date: YYYY-MM-DD, time: HH:MM.\"\"\"\n",
        "    for event in _calendar_events:\n",
        "        if event[\"date\"] == date and event[\"time\"] == time:\n",
        "            return f\"Conflict: '{event['title']}' already at {date} {time}\"\n",
        "    new_event = {\"title\": title, \"date\": date, \"time\": time, \"location\": location}\n",
        "    _calendar_events.append(new_event)\n",
        "    return f\"Created '{title}' on {date} at {time} in {location}\"\n",
        "\n",
        "print(\"✅ Calendar tools defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. LangChain agent\n",
        "\n",
        "Create an agent with **LangChain**: `create_agent(model, tools, system_prompt)`. Memory is optional (pass a checkpointer for conversation memory)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LangChain agent created\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a helpful calendar assistant. You can:\n",
        "- Read events with read_calendar\n",
        "- Create events with write_calendar\n",
        "Use YYYY-MM-DD and HH:MM. Check for conflicts before creating. Current year: 2026.\"\"\"\n",
        "\n",
        "langchain_agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[read_calendar, write_calendar],\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        ")\n",
        "\n",
        "print(\"✅ LangChain agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Schedule a team standup on 2026-03-15 at 09:00 in Room A\n",
            "Agent: The team standup has been scheduled for 2026-03-15 at 09:00 in Room A.\n"
          ]
        }
      ],
      "source": [
        "# Run the LangChain agent\n",
        "result = langchain_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Schedule a team standup on 2026-03-15 at 09:00 in Room A\"}]\n",
        "})\n",
        "print(\"User:\", \"Schedule a team standup on 2026-03-15 at 09:00 in Room A\")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. DeepAgents\n",
        "\n",
        "Create the **same** agent with **DeepAgents**: `create_deep_agent(...)`. You get the same tools plus:\n",
        "\n",
        "- **write_todos** – plan multi-step tasks\n",
        "- **File system** – `ls`, `read_file`, `write_file`, `edit_file` in agent state\n",
        "- **task** – delegate to subagents (optional)\n",
        "\n",
        "Pass a **checkpointer** (e.g. `MemorySaver()`) for conversation memory; both agents can run with or without it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DeepAgent created (with write_todos + file system)\n"
          ]
        }
      ],
      "source": [
        "from deepagents import create_deep_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "_calendar_events: List[Dict] = []\n",
        "\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "DEEP_SYSTEM_PROMPT = \"\"\"You are a helpful calendar assistant with planning. You can:\n",
        "- read_calendar, write_calendar (same as before)\n",
        "- write_todos: break down complex tasks (built-in)\n",
        "- File tools: ls, read_file, write_file, edit_file (built-in)\n",
        "Use write_todos for multi-step requests. Current year: 2026.\"\"\"\n",
        "\n",
        "deep_agent = create_deep_agent(\n",
        "    model=model,\n",
        "    tools=[read_calendar, write_calendar],\n",
        "    system_prompt=DEEP_SYSTEM_PROMPT,\n",
        "    checkpointer=checkpointer,\n",
        ")\n",
        "\n",
        "print(\"✅ DeepAgent created (with write_todos + file system)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: I have scheduled the following meetings for next week in Room B:\n",
            "\n",
            "- **Monday, October 2, 2026** at **10:00**\n",
            "- **Wednesday, October 4, 2026** at **14:00**\n",
            "- **Friday, October 6, 2026** at **16:00**\n"
          ]
        }
      ],
      "source": [
        "# Run the DeepAgent (use config with thread_id for memory)\n",
        "config = {\"configurable\": {\"thread_id\": \"comparison-thread-1\"}}\n",
        "\n",
        "result = deep_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Schedule three meetings next week: Mon 10:00, Wed 14:00, Fri 16:00. All in Room B. Then list what you scheduled.\"}]\n",
        "}, config=config)\n",
        "\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Best practices (DeepAgents)\n",
        "\n",
        "**When to use subagents**\n",
        "\n",
        "- **Context preservation** – Multi-step tasks (e.g. many web searches) fill the main agent’s context; subagents run in isolation and return only the final result.\n",
        "- **Specialization** – Give a subagent domain-specific instructions and a focused tool set (e.g. only search).\n",
        "- **Multi-model** – Subagents can use a different model (e.g. smaller/faster) than the main agent.\n",
        "- **Parallelization** – Multiple subagents can run in parallel and hand results back to the main agent.\n",
        "\n",
        "**Subagent design**\n",
        "\n",
        "- **Descriptions**: Clear and specific so the main agent knows when to call which subagent.  \n",
        "  ✅ \"Conducts in-depth research using web search and synthesizes findings into a concise summary\"  \n",
        "  ❌ \"Does research\"\n",
        "- **System prompts**: Include tool-usage guidance and output format (e.g. \"Keep response under 500 words\", \"Cite sources\").\n",
        "- **Minimal tool sets**: Only give each subagent the tools it needs (e.g. research subagent gets search only, not calendar + search + email)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Subagents: research with Tavily\n",
        "\n",
        "Subagents isolate work: the **research subagent** does multiple web searches in its own context and returns a single summary to the main agent. That keeps the main agent’s context small and avoids “context bloat.”\n",
        "\n",
        "Here we use **Tavily** for search. For real search: set `TAVILY_API_KEY` in `.env` and install `tavily-python` (`pip install tavily-python`). Without the API key, a mock is used so the notebook still runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DeepAgent with research subagent created (Tavily: real if TAVILY_API_KEY set, else mock)\n"
          ]
        }
      ],
      "source": [
        "# Tavily search tool: real API if TAVILY_API_KEY is set, else mock\n",
        "def _tavily_search_impl(query: str, max_results: int = 4) -> str:\n",
        "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "    if api_key:\n",
        "        try:\n",
        "            from tavily import TavilyClient\n",
        "            client = TavilyClient(api_key=api_key)\n",
        "            response = client.search(query=query, max_results=max_results)\n",
        "            results = response.get(\"results\", [])\n",
        "            if not results:\n",
        "                return f\"No results for: {query}\"\n",
        "            return \"\\n\\n\".join(\n",
        "                f\"[{i+1}] {r.get('title', '')}\\n{r.get('content', '')}\\nURL: {r.get('url', '')}\"\n",
        "                for i, r in enumerate(results)\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return f\"Tavily search error: {e}. Using mock.\"\n",
        "    # Mock for demo without API key\n",
        "    return f'''Search results for \"{query}\":\n",
        "1. Example Corp - Series B $50M (2025), CEO Jane Doe. Competitors: Acme Inc, Beta LLC.\n",
        "2. Recent news: Example Corp announced partnership with TechCo (March 2025).\n",
        "URLs: https://example.com/company, https://example.com/news'''\n",
        "\n",
        "@tool\n",
        "def tavily_search(query: str, max_results: int = 4) -> str:\n",
        "    \"\"\"Search the web for current information. Use for company research, events, or general lookup.\"\"\"\n",
        "    return _tavily_search_impl(query, max_results)\n",
        "\n",
        "# Research subagent: focused tools + clear instructions\n",
        "research_subagent = {\n",
        "    \"name\": \"research-specialist\",\n",
        "    \"description\": \"Conducts in-depth research using web search and synthesizes findings into a concise summary. Use when you need company info, events, or multi-query research.\",\n",
        "    \"system_prompt\": \"\"\"You are a thorough researcher. Your job is to:\n",
        "1. Break down the research question into 2-4 focused search queries\n",
        "2. Use tavily_search to gather information\n",
        "3. Synthesize findings into a concise summary\n",
        "4. Cite sources (title + URL) when making claims\n",
        "\n",
        "Output format: Summary (2-3 short paragraphs), Key facts (bullets), Sources (with URLs). Keep response under 400 words.\"\"\",\n",
        "    \"tools\": [tavily_search],\n",
        "    \"model\": model,\n",
        "}\n",
        "\n",
        "# Supervisor agent with subagent\n",
        "checkpointer2 = MemorySaver()\n",
        "supervisor_prompt = \"\"\"You are a coordinator. You have:\n",
        "- read_calendar, write_calendar for scheduling\n",
        "- task: delegate to subagents\n",
        "\n",
        "Use the 'task' tool with name \"research-specialist\" when the user asks for company research, web search, or \"find out about X\". Use calendar tools for scheduling. Return a clear, consolidated answer.\"\"\"\n",
        "\n",
        "agent_with_subagent = create_deep_agent(\n",
        "    model=model,\n",
        "    tools=[read_calendar, write_calendar, tavily_search],\n",
        "    system_prompt=supervisor_prompt,\n",
        "    checkpointer=checkpointer2,\n",
        "    subagents=[research_subagent],\n",
        ")\n",
        "print(\"✅ DeepAgent with research subagent created (Tavily: real if TAVILY_API_KEY set, else mock)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Research LangChain Inc: funding rounds, CEO, and main competitors. Give me a short summary with sources.\n",
            "Agent: Here's a summary of the research on LangChain Inc., focusing on its funding rounds, CEO, and main competitors:\n",
            "\n",
            "### Summary\n",
            "LangChain Inc. has emerged as a significant player in the AI infrastructure market, successfully raising a total of **$135 million** across three funding rounds. The most notable round was a **$125 million Series B**, which valued the company at **$1.1 billion**. This funding has been crucial for its growth and the development of tools for building AI agents and applications. The company is supported by prominent investors, including Sequoia Capital and Benchmark, indicating strong confidence in its business model and market potential ([Latenode](https://latenode.com/blog/ai-frameworks-technical-infrastructure/langchain-setup-tools-agents-memory/langchain-funding-valuation-2025-complete-financial-overview), [TexAu](https://www.texau.com/profiles/lang-chain)).\n",
            "\n",
            "The current CEO of LangChain is **Harrison Chase**, who co-founded the company. He is joined by co-founder **Ankush Gola** and a team of executives who guide the company's strategic direction and operations ([CB Insights](https://www.cbinsights.com/company/langchain/people), [CapitalG](https://www.capitalg.com/portfolio/langchain)).\n",
            "\n",
            "In terms of competition, LangChain faces several notable rivals in the AI development space, including **LlamaIndex**, **Haystack**, **Semantic Kernel**, and **AutoGen**. These competitors offer various features tailored to specific use cases, such as document-heavy applications and enterprise integration, which may provide advantages over LangChain in certain scenarios ([CheckThat](https://checkthat.ai/brands/langchain/alternatives), [Budibase](https://budibase.com/blog/alternatives/langchain/)).\n",
            "\n",
            "### Key Facts\n",
            "- **Funding**: $135 million raised in three rounds; $125 million Series B round valued at $1.1 billion.\n",
            "- **CEO**: Harrison Chase, co-founder.\n",
            "- **Leadership Team**: Includes co-founder Ankush Gola and other executives.\n",
            "- **Main Competitors**: LlamaIndex, Haystack, Semantic Kernel, AutoGen.\n",
            "\n",
            "### Sources\n",
            "1. [LangChain Funding & Valuation 2025: Complete Financial Overview](https://latenode.com/blog/ai-frameworks-technical-infrastructure/langchain-setup-tools-agents-memory/langchain-funding-valuation-2025-complete-financial-overview)\n",
            "2. [How Much Did LangChain Raise? Funding & Key Investors - TexAu](https://www.texau.com/profiles/lang-chain)\n",
            "3. [LangChain Management Team - CB Insights](https://www.cbinsights.com/company/langchain/people)\n",
            "4. [Top 5 LangChain Alternatives Compared - CheckThat](https://checkthat.ai/brands/langchain/alternatives)\n"
          ]
        }
      ],
      "source": [
        "# Example: delegate company research to the subagent\n",
        "config_super = {\"configurable\": {\"thread_id\": \"subagent-demo-1\"}}\n",
        "result = agent_with_subagent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Research LangChain Inc: funding rounds, CEO, and main competitors. Give me a short summary with sources.\"}]\n",
        "}, config=config_super)\n",
        "print(\"User: Research LangChain Inc: funding rounds, CEO, and main competitors. Give me a short summary with sources.\")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Skills: domain-specific web search (company intelligence)\n",
        "\n",
        "**Skills** provide progressive disclosure: the agent sees skill **names and descriptions** first, and loads full instructions only when a skill is needed. That keeps the context window smaller.\n",
        "\n",
        "This repo includes a **company intelligence** skill for domain-specific web search: how to query, what to look for, and how to format answers (funding, leadership, competitors, sources). Skill path: `.deepagents/skills/company-intelligence/SKILL.md`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DeepAgent with skills loaded from /Users/mperini/Projects/workshop-planner-agent/.deepagents/skills\n"
          ]
        }
      ],
      "source": [
        "# Load skills from the project's .deepagents/skills directory\n",
        "# Backend + skills API may vary by deepagents version; see docs for your version.\n",
        "import os\n",
        "_skills_path = os.path.abspath(\".deepagents/skills\")\n",
        "agent_with_skills = None\n",
        "if os.path.isdir(_skills_path):\n",
        "    try:\n",
        "        from deepagents.backends import FilesystemBackend\n",
        "        _root = os.path.abspath(\".\")\n",
        "        \n",
        "        agent_with_skills = create_deep_agent(\n",
        "            model=model,\n",
        "            tools=[tavily_search],\n",
        "            system_prompt=\"You are a research assistant. Use the company-intelligence skill when the user asks about companies to properly understand how to perform a company intelligence search.\",\n",
        "            checkpointer=MemorySaver(),\n",
        "            backend=FilesystemBackend(root_dir=_root),\n",
        "            skills=[_skills_path],\n",
        "        )\n",
        "\n",
        "        print(\"✅ DeepAgent with skills loaded from\", _skills_path)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not load skills (backend/skills API may differ):\", e)\n",
        "else:\n",
        "    print(\"⚠️ .deepagents/skills not found; add SKILL.md files there to use skills\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent (with company-intelligence skill): ### LangChain Inc Overview\n",
            "\n",
            "- **Funding Rounds**: LangChain has raised a total of **$260 million** across **4 funding rounds**. The latest funding round was a **$125 million Series B** on **October 20, 2025**. Notable investors include **Sequoia Capital**, **IVP**, and **Sapphire Ventures**.\n",
            "\n",
            "- **CEO**: The current CEO of LangChain is **Harrison Chase**.\n",
            "\n",
            "- **Main Competitors**: LangChain ranks **2nd** among **538 active competitors** in the AI developer tools market. Some of its notable competitors include:\n",
            "  - **OpenAI**\n",
            "  - **Cohere**\n",
            "  - **Hugging Face**\n",
            "  - **Anthropic**\n",
            "  - **Google DeepMind**\n",
            "\n",
            "### Additional Information\n",
            "LangChain is recognized for its open-source framework that facilitates the development of AI applications using large language models (LLMs). The company aims to pro...\n"
          ]
        }
      ],
      "source": [
        "# Optional: run the agent with company-intelligence skill (follows SKILL.md for query + output format)\n",
        "if agent_with_skills:\n",
        "    cfg = {\"configurable\": {\"thread_id\": \"skills-demo-2\"}}\n",
        "    r = agent_with_skills.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Research LangChain Inc: funding rounds, CEO, and main competitors.\"}]\n",
        "    }, config=cfg)\n",
        "    print(\"Agent (with company-intelligence skill):\", r[\"messages\"][-1].content[:800] + \"...\" if len(r[\"messages\"][-1].content) > 800 else r[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "| | LangChain | DeepAgents |\n",
        "|---|-----------|------------|\n",
        "| **API** | `create_agent(model, tools, system_prompt)` | `create_deep_agent(...)` |\n",
        "| **Planning** | Manual in prompt | `write_todos` built-in |\n",
        "| **Context** | Conversation only | + file system in state |\n",
        "| **Delegation** | Custom (e.g. supervisor) | `task` tool + subagents |\n",
        "| **Procedures** | In system prompt | **Skills** (progressive disclosure) |\n",
        "\n",
        "**Takeaways**\n",
        "\n",
        "- **LangChain** agents are flexible: use for tool-calling, add memory (checkpointer), middleware, and custom patterns as needed.\n",
        "- Use **DeepAgents** when you want planning, in-conversation files, subagents, and skills.\n",
        "- **Subagents**: isolate context and specialize (e.g. research subagent with Tavily); give clear descriptions and minimal tool sets.\n",
        "- **Skills**: store procedures in `.deepagents/skills/*/SKILL.md`; the agent sees descriptions first and loads full instructions when needed (e.g. company-intelligence for domain-specific web search)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
