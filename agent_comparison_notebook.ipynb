{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agent Comparison: LangChain vs DeepAgents\n",
        "\n",
        "This notebook shows how to build the **same calendar agent** in two ways:\n",
        "\n",
        "1. **LangChain** – `create_agent` with model, tools, and system prompt\n",
        "2. **DeepAgents** – `create_deep_agent` with built-in planning, file system, and optional subagents\n",
        "\n",
        "Both use the same tools and model; DeepAgents add planning and context management on top."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. LangSmith setup\n",
        "\n",
        "LangSmith gives you tracing, debugging, and visibility into agent runs.\n",
        "\n",
        "**Setup steps:**\n",
        "\n",
        "1. Sign up at [smith.langchain.com](https://smith.langchain.com)\n",
        "2. Create an API key: **Settings → API Keys → Create API Key**\n",
        "3. Add to your `.env` (see `.env.example`):\n",
        "   ```\n",
        "   LANGSMITH_API_KEY=your_api_key_here\n",
        "   LANGSMITH_TRACING=true\n",
        "   LANGSMITH_PROJECT=your-project-name\n",
        "   ```\n",
        "\n",
        "See `.env.example` in the project root. With this in place, runs are automatically sent to LangSmith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LangSmith configured (traces will appear in your project)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# Optional: enable tracing if not set in .env\n",
        "os.environ.setdefault(\"LANGSMITH_TRACING\", \"true\")\n",
        "os.environ.setdefault(\"LANGSMITH_PROJECT\", \"agent-comparison\")\n",
        "\n",
        "if os.getenv(\"LANGSMITH_API_KEY\"):\n",
        "    print(\"✅ LangSmith configured (traces will appear in your project)\")\n",
        "else:\n",
        "    print(\"⚠️ LANGSMITH_API_KEY not set — add it to .env for tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment and shared pieces\n",
        "\n",
        "Imports, model, and shared calendar tools used by both agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model: ChatOpenAI\n",
            "✅ Calendar tools defined\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Model (same for both agents)\n",
        "model = init_chat_model(\"gpt-4o-mini\", temperature=0)\n",
        "print(f\"✅ Model: {model.__class__.__name__}\")\n",
        "\n",
        "# Shared in-memory calendar\n",
        "_calendar_events: List[Dict] = []\n",
        "\n",
        "@tool\n",
        "def read_calendar(date: str = None) -> str:\n",
        "    \"\"\"Read calendar events. If date is provided, filter events for that date (YYYY-MM-DD).\"\"\"\n",
        "    if date:\n",
        "        filtered = [e for e in _calendar_events if e.get(\"date\") == date]\n",
        "        if not filtered:\n",
        "            return f\"No events found for {date}\"\n",
        "        return \"\\n\".join([f\"- {e['title']} on {e['date']} at {e['time']} in {e.get('location', 'N/A')}\" for e in filtered])\n",
        "    if not _calendar_events:\n",
        "        return \"No events in calendar\"\n",
        "    return \"\\n\".join([f\"- {e['title']} on {e['date']} at {e['time']} in {e.get('location', 'N/A')}\" for e in _calendar_events])\n",
        "\n",
        "@tool\n",
        "def write_calendar(title: str, date: str, time: str, location: str = \"\") -> str:\n",
        "    \"\"\"Create a new calendar event. Date: YYYY-MM-DD, time: HH:MM.\"\"\"\n",
        "    for event in _calendar_events:\n",
        "        if event[\"date\"] == date and event[\"time\"] == time:\n",
        "            return f\"Conflict: '{event['title']}' already at {date} {time}\"\n",
        "    new_event = {\"title\": title, \"date\": date, \"time\": time, \"location\": location}\n",
        "    _calendar_events.append(new_event)\n",
        "    return f\"Created '{title}' on {date} at {time} in {location}\"\n",
        "\n",
        "print(\"✅ Calendar tools defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. LangChain agent\n",
        "\n",
        "Create an agent with **LangChain**: `create_agent(model, tools, system_prompt)`. No memory by default; each `invoke` is stateless unless you pass a checkpointer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LangChain agent created\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a helpful calendar assistant. You can:\n",
        "- Read events with read_calendar\n",
        "- Create events with write_calendar\n",
        "Use YYYY-MM-DD and HH:MM. Check for conflicts before creating. Current year: 2026.\"\"\"\n",
        "\n",
        "langchain_agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[read_calendar, write_calendar],\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        ")\n",
        "\n",
        "print(\"✅ LangChain agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Schedule a team standup on 2026-03-15 at 09:00 in Room A\n",
            "Agent: The team standup has been scheduled for 2026-03-15 at 09:00 in Room A.\n"
          ]
        }
      ],
      "source": [
        "# Run the LangChain agent\n",
        "result = langchain_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Schedule a team standup on 2026-03-15 at 09:00 in Room A\"}]\n",
        "})\n",
        "print(\"User:\", \"Schedule a team standup on 2026-03-15 at 09:00 in Room A\")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. DeepAgents\n",
        "\n",
        "Create the **same** agent with **DeepAgents**: `create_deep_agent(...)`. You get the same tools plus:\n",
        "\n",
        "- **write_todos** – plan multi-step tasks\n",
        "- **File system** – `ls`, `read_file`, `write_file`, `edit_file` in agent state\n",
        "- **task** – delegate to subagents (optional)\n",
        "\n",
        "A **checkpointer** is required so the agent has conversation memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DeepAgent created (with write_todos + file system)\n"
          ]
        }
      ],
      "source": [
        "from deepagents import create_deep_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "_calendar_events: List[Dict] = []\n",
        "\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "DEEP_SYSTEM_PROMPT = \"\"\"You are a helpful calendar assistant with planning. You can:\n",
        "- read_calendar, write_calendar (same as before)\n",
        "- write_todos: break down complex tasks (built-in)\n",
        "- File tools: ls, read_file, write_file, edit_file (built-in)\n",
        "Use write_todos for multi-step requests. Current year: 2026.\"\"\"\n",
        "\n",
        "deep_agent = create_deep_agent(\n",
        "    model=model,\n",
        "    tools=[read_calendar, write_calendar],\n",
        "    system_prompt=DEEP_SYSTEM_PROMPT,\n",
        "    checkpointer=checkpointer,\n",
        ")\n",
        "\n",
        "print(\"✅ DeepAgent created (with write_todos + file system)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: I have scheduled the following meetings for next week in Room B:\n",
            "\n",
            "1. **Monday, October 2, 2026** at **10:00**\n",
            "2. **Wednesday, October 4, 2026** at **14:00**\n",
            "3. **Friday, October 6, 2026** at **16:00**\n"
          ]
        }
      ],
      "source": [
        "# Run the DeepAgent (use config with thread_id for memory)\n",
        "config = {\"configurable\": {\"thread_id\": \"comparison-thread-1\"}}\n",
        "\n",
        "result = deep_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Schedule three meetings next week: Mon 10:00, Wed 14:00, Fri 16:00. All in Room B. Then list what you scheduled.\"}]\n",
        "}, config=config)\n",
        "\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Best practices (DeepAgents)\n",
        "\n",
        "**When to use subagents**\n",
        "\n",
        "- **Context preservation** – Multi-step tasks (e.g. many web searches) fill the main agent’s context; subagents run in isolation and return only the final result.\n",
        "- **Specialization** – Give a subagent domain-specific instructions and a focused tool set (e.g. only search).\n",
        "- **Multi-model** – Subagents can use a different model (e.g. smaller/faster) than the main agent.\n",
        "- **Parallelization** – Multiple subagents can run in parallel and hand results back to the main agent.\n",
        "\n",
        "**Subagent design**\n",
        "\n",
        "- **Descriptions**: Clear and specific so the main agent knows when to call which subagent.  \n",
        "  ✅ \"Conducts in-depth research using web search and synthesizes findings into a concise summary\"  \n",
        "  ❌ \"Does research\"\n",
        "- **System prompts**: Include tool-usage guidance and output format (e.g. \"Keep response under 500 words\", \"Cite sources\").\n",
        "- **Minimal tool sets**: Only give each subagent the tools it needs (e.g. research subagent gets search only, not calendar + search + email)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Subagents: research with Tavily\n",
        "\n",
        "Subagents isolate work: the **research subagent** does multiple web searches in its own context and returns a single summary to the main agent. That keeps the main agent’s context small and avoids “context bloat.”\n",
        "\n",
        "Here we use **Tavily** for search. For real search: set `TAVILY_API_KEY` in `.env` and install `tavily-python` (`pip install tavily-python`). Without the API key, a mock is used so the notebook still runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DeepAgent with research subagent created (Tavily: real if TAVILY_API_KEY set, else mock)\n"
          ]
        }
      ],
      "source": [
        "# Tavily search tool: real API if TAVILY_API_KEY is set, else mock\n",
        "def _tavily_search_impl(query: str, max_results: int = 4) -> str:\n",
        "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "    if api_key:\n",
        "        try:\n",
        "            from tavily import TavilyClient\n",
        "            client = TavilyClient(api_key=api_key)\n",
        "            response = client.search(query=query, max_results=max_results)\n",
        "            results = response.get(\"results\", [])\n",
        "            if not results:\n",
        "                return f\"No results for: {query}\"\n",
        "            return \"\\n\\n\".join(\n",
        "                f\"[{i+1}] {r.get('title', '')}\\n{r.get('content', '')}\\nURL: {r.get('url', '')}\"\n",
        "                for i, r in enumerate(results)\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return f\"Tavily search error: {e}. Using mock.\"\n",
        "    # Mock for demo without API key\n",
        "    return f'''Search results for \"{query}\":\n",
        "1. Example Corp - Series B $50M (2025), CEO Jane Doe. Competitors: Acme Inc, Beta LLC.\n",
        "2. Recent news: Example Corp announced partnership with TechCo (March 2025).\n",
        "URLs: https://example.com/company, https://example.com/news'''\n",
        "\n",
        "@tool\n",
        "def tavily_search(query: str, max_results: int = 4) -> str:\n",
        "    \"\"\"Search the web for current information. Use for company research, events, or general lookup.\"\"\"\n",
        "    return _tavily_search_impl(query, max_results)\n",
        "\n",
        "# Research subagent: focused tools + clear instructions\n",
        "research_subagent = {\n",
        "    \"name\": \"research-specialist\",\n",
        "    \"description\": \"Conducts in-depth research using web search and synthesizes findings into a concise summary. Use when you need company info, events, or multi-query research.\",\n",
        "    \"system_prompt\": \"\"\"You are a thorough researcher. Your job is to:\n",
        "1. Break down the research question into 2-4 focused search queries\n",
        "2. Use tavily_search to gather information\n",
        "3. Synthesize findings into a concise summary\n",
        "4. Cite sources (title + URL) when making claims\n",
        "\n",
        "Output format: Summary (2-3 short paragraphs), Key facts (bullets), Sources (with URLs). Keep response under 400 words.\"\"\",\n",
        "    \"tools\": [tavily_search],\n",
        "    \"model\": model,\n",
        "}\n",
        "\n",
        "# Supervisor agent with subagent\n",
        "checkpointer2 = MemorySaver()\n",
        "supervisor_prompt = \"\"\"You are a coordinator. You have:\n",
        "- read_calendar, write_calendar for scheduling\n",
        "- task: delegate to subagents\n",
        "\n",
        "Use the 'task' tool with name \"research-specialist\" when the user asks for company research, web search, or \"find out about X\". Use calendar tools for scheduling. Return a clear, consolidated answer.\"\"\"\n",
        "\n",
        "agent_with_subagent = create_deep_agent(\n",
        "    model=model,\n",
        "    tools=[read_calendar, write_calendar, tavily_search],\n",
        "    system_prompt=supervisor_prompt,\n",
        "    checkpointer=checkpointer2,\n",
        "    subagents=[research_subagent],\n",
        ")\n",
        "print(\"✅ DeepAgent with research subagent created (Tavily: real if TAVILY_API_KEY set, else mock)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Research Example Corp: funding, leadership, recent news.\n",
            "Agent: Here's a summary of the recent research on Orange.com, focusing on its funding, leadership, and recent news:\n",
            "\n",
            "### Summary\n",
            "Orange S.A., a prominent telecommunications operator, has recently made notable advancements in funding and leadership. The company issued €1.5 billion in bonds, which includes a €750 million sustainable bond, to bolster its financial strategy and operations. This move underscores Orange's commitment to sustainable finance and its efforts to enhance its capital structure. Additionally, Orange has signed a binding agreement to acquire full ownership of MasOrange, a significant player in the Spanish telecommunications market, further strengthening its position in Europe.\n",
            "\n",
            "In terms of leadership, Christel Heydemann serves as the CEO, leading a diverse executive team that is responsible for implementing the company's strategic vision. This team comprises experienced professionals from various sectors, ensuring a robust governance structure that supports Orange's growth and innovation initiatives. Recent news also highlights Orange's focus on cybersecurity, as the company now protects 140,000 workstations across its group, demonstrating its commitment to enhancing digital security for its clients.\n",
            "\n",
            "### Key Facts\n",
            "- **Funding**: Orange issued €1.5 billion in bonds, including a €750 million sustainable bond.\n",
            "- **Acquisition**: Signed an agreement to acquire full ownership of MasOrange in Spain.\n",
            "- **Leadership**: Christel Heydemann is the CEO, supported by a diverse executive team.\n",
            "- **Cybersecurity**: Orange now protects 140,000 workstations across its group.\n",
            "\n",
            "### Sources\n",
            "- [Orange Newsroom](https://newsroom.orange.com/orange-issued-eur15-billion-in-the-bond-market-including-a-eur750-million-sustainable-bond/)\n",
            "- [Orange Governance](https://www.orange.com/en/our-governance)\n",
            "- [Orange Press](https://www.orange.com/en/press)\n",
            "\n",
            "If you need more detailed information or further assistance, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "# Example: delegate company research to the subagent\n",
        "config_super = {\"configurable\": {\"thread_id\": \"subagent-demo-1\"}}\n",
        "result = agent_with_subagent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Research langchain.com Company: funding, leadership, and any recent news. Give me a short summary with sources.\"}]\n",
        "}, config=config_super)\n",
        "print(\"User: Research langchain.com Company: funding, leadership, recent news.\")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Skills: domain-specific web search (company intelligence)\n",
        "\n",
        "**Skills** provide progressive disclosure: the agent sees skill **names and descriptions** first, and loads full instructions only when a skill is needed. That keeps the context window smaller.\n",
        "\n",
        "This repo includes a **company intelligence** skill for domain-specific web search: how to query, what to look for, and how to format answers (funding, leadership, competitors, sources). Skill path: `.deepagents/skills/company-intelligence/SKILL.md`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Could not load skills (backend/skills API may differ): create_deep_agent() got an unexpected keyword argument 'backend'\n"
          ]
        }
      ],
      "source": [
        "# Load skills from the project's .deepagents/skills directory\n",
        "# Backend + skills API may vary by deepagents version; see docs for your version.\n",
        "import os\n",
        "_skills_path = os.path.abspath(\".deepagents/skills\")\n",
        "agent_with_skills = None\n",
        "if os.path.isdir(_skills_path):\n",
        "    try:\n",
        "        from deepagents.backends import FilesystemBackend\n",
        "        _root = os.path.abspath(\".\")\n",
        "\n",
        "        from deepagents import create_deep_agent\n",
        "        from deepagents.backends import FilesystemBackend\n",
        "        \n",
        "        agent_with_skills = create_deep_agent(\n",
        "            model=model,\n",
        "            tools=[tavily_search],\n",
        "            system_prompt=SYSTEM_PROMPT,\n",
        "            checkpointer=MemorySaver(),\n",
        "            backend=FilesystemBackend(root_dir=_root),\n",
        "            skills=[_skills_path],\n",
        "        )\n",
        "\n",
        "        result = agent_with_skills.invoke(...)\n",
        "\n",
        "        print(\"✅ DeepAgent with skills loaded from\", _skills_path)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not load skills (backend/skills API may differ):\", e)\n",
        "else:\n",
        "    print(\"⚠️ .deepagents/skills not found; add SKILL.md files there to use skills\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: run the agent with company-intelligence skill (follows SKILL.md for query + output format)\n",
        "if agent_with_skills:\n",
        "    cfg = {\"configurable\": {\"thread_id\": \"skills-demo-1\"}}\n",
        "    r = agent_with_skills.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Research Acme Inc: funding rounds, CEO, and main competitors. Use the company intelligence skill.\"}]\n",
        "    }, config=cfg)\n",
        "    print(\"Agent (with company-intelligence skill):\", r[\"messages\"][-1].content[:800] + \"...\" if len(r[\"messages\"][-1].content) > 800 else r[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "| | LangChain | DeepAgents |\n",
        "|---|-----------|------------|\n",
        "| **API** | `create_agent(model, tools, system_prompt)` | `create_deep_agent(..., checkpointer=...)` |\n",
        "| **Memory** | Optional (pass checkpointer) | Required (checkpointer) |\n",
        "| **Planning** | Manual in prompt | `write_todos` built-in |\n",
        "| **Context** | Conversation only | + file system in state |\n",
        "| **Delegation** | Custom (e.g. supervisor) | `task` tool + subagents |\n",
        "| **Procedures** | In system prompt | **Skills** (progressive disclosure) |\n",
        "\n",
        "**Takeaways**\n",
        "\n",
        "- Use **LangChain** for simple, stateless tool use.\n",
        "- Use **DeepAgents** when you want planning, in-conversation files, subagents, and skills.\n",
        "- **Subagents**: isolate context and specialize (e.g. research subagent with Tavily); give clear descriptions and minimal tool sets.\n",
        "- **Skills**: store procedures in `.deepagents/skills/*/SKILL.md`; the agent sees descriptions first and loads full instructions when needed (e.g. company-intelligence for domain-specific web search)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
